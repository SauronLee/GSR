{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e3151bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "07fd114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ea179bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = 186186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d87aaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_embeddings(filepath):\n",
    "# load pretrained embeddings\n",
    "    count = 0\n",
    "    word_to_id_lang = {}\n",
    "    id_to_word_lang = {}\n",
    "    vectors_lang = []\n",
    "    with io.open(filepath, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                header = line.split()\n",
    "                assert len(header) == 2\n",
    "                assert dimension == int(header[1])\n",
    "            else:\n",
    "                if i%20000 == 0 :\n",
    "                        print(\"Reading %s file %0.2f percent done\"%(filepath,float(i)/20000.0))\n",
    "                word, vector_rep = line.rstrip().split(' ', 1)\n",
    "                word = word.lower()\n",
    "                vector_rep = np.fromstring(vector_rep, sep=' ')\n",
    "                if vector_rep.shape[0] == dimension :\n",
    "                    if word not in word_to_id_lang :\n",
    "                        word_to_id_lang[word] = count\n",
    "                        vectors_lang.append(vector_rep[None])\n",
    "                        count+=1\n",
    "                    if count == vocab_length :\n",
    "                        break\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "    id_to_word_lang = {value: key for key, value in word_to_id_lang.items()}\n",
    "    embeddings = np.concatenate(vectors_lang, 0)\n",
    "    return word_to_id_lang,id_to_word_lang,embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "544b10e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./simi_sememe.embedding file 1.00 percent done\n",
      "Reading ./simi_sememe.embedding file 2.00 percent done\n",
      "Reading ./simi_sememe.embedding file 3.00 percent done\n",
      "Reading ./simi_sememe.embedding file 4.00 percent done\n",
      "Reading ./simi_sememe.embedding file 5.00 percent done\n",
      "Reading ./simi_sememe.embedding file 6.00 percent done\n",
      "Reading ./simi_sememe.embedding file 7.00 percent done\n",
      "Reading ./simi_sememe.embedding file 8.00 percent done\n",
      "Reading ./simi_sememe.embedding file 9.00 percent done\n"
     ]
    }
   ],
   "source": [
    "w2i,i2w,embedding=load_pretrained_embeddings(\"./simi_sememe.embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c2c42cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w-年'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "102dda4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8fe3c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_sim = cosine_similarity(embedding[w2i[\"w-年\"]].reshape(1,-1),embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c07c067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_indices = comp_sim.argsort().flatten()[-10:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4df11b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w-改称\n",
      "w-元年\n",
      "d-ゴーイン・バック・トゥ・ニューオーリンズ\n",
      "w-同年\n",
      "w-月\n",
      "w-昭和\n",
      "w-なり年\n",
      "w-後年\n",
      "w-翌年\n",
      "w-年\n"
     ]
    }
   ],
   "source": [
    "for i in similar_indices:\n",
    "    print(i2w[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce6f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bb1cbb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_graph_dic = {}\n",
    "\n",
    "for line in open('../graph_building/doc.graph'):\n",
    "    source = line.split()[0].split(\"-\")[1]\n",
    "    taget = line.split()[1].split(\"-\")[1]\n",
    "    raletion = line.split()[2]\n",
    "    doc_graph_dic[source+\"-\"+taget]=raletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0f8f7949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('月-ロデリック・アリアス', '1.2651257248936925')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc_graph_dic.items())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e9df9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_graph_dic = {}\n",
    "\n",
    "for line in open('../graph_building/topic.graph'):\n",
    "    source = \"\".join(line.split()[0:-2]).split(\"-\")[1]\n",
    "    taget = line.split()[-2].split(\"-\")[1]\n",
    "    raletion = line.split()[-1]\n",
    "    topic_graph_dic[source+\"|||\"+taget]=raletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0569d01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ロデリック・アリアス-2', '0.1184195660024464')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(topic_graph_dic.items())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "05d4e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def topic_to_word(topic):\n",
    "    words_embedding =[]\n",
    "    doc_list = []\n",
    "    for key, value in topic_graph_dic.items():\n",
    "        if topic == key.split(\"-\")[1] and float(value) > 0.05:\n",
    "            doc_list.append(key.split(\"-\")[0])\n",
    "    for key, value in doc_graph_dic.items():\n",
    "        if key.split(\"-\")[1] in doc_list and key.split(\"-\")[0] !=\"\":\n",
    "            word=key.split(\"-\")[0]\n",
    "            \n",
    "            words_embedding.append(embedding[w2i[\"w-\"+word]])\n",
    "    comp_sim = cosine_similarity(embedding[w2i[\"t-\"+topic]].reshape(1,-1),words_embedding)\n",
    "    similar_indices = comp_sim.argsort().flatten()[-10:]\n",
    "    for i in similar_indices:\n",
    "        print(i2w[i])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "27874a37",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "370996",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_612/3413637420.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtopic_to_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"6\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_612/1255583568.py\u001b[0m in \u001b[0;36mtopic_to_word\u001b[0;34m(topic)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msimilar_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilar_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi2w\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 370996"
     ]
    }
   ],
   "source": [
    "topic_to_word(\"6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b0149e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i['w-日']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6365f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiki_corpus",
   "language": "python",
   "name": "wiki_corpus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
